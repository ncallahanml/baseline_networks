{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e9272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from copy import deepcopy\n",
    "\n",
    "from wave_generator import WaveGen\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from ray import train, tune\n",
    "# from ray.train import Checkpoint, session\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309db4f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def torch_train_test_split(*tensors, split=.8):\n",
    "    n_samples = tensors[0].shape[0]\n",
    "    train_size = int(split * n_samples)\n",
    "    test_size = n_samples - train_size\n",
    "    rand_indices = torch.randperm(n_samples)\n",
    "    train_indices, test_indices = torch.split(rand_indices, [train_size, test_size])\n",
    "    assert train_indices.shape[0] == train_size, f'{train_indices.shape} != {train_size}'\n",
    "    assert test_indices.shape[0] == n_samples - train_size, f'{test_indices.shape} != {n_samples - train_size}'\n",
    "\n",
    "    data_tensors = list()\n",
    "    for tensor in tensors:\n",
    "        assert tensor.shape[0] == n_samples\n",
    "        train_data = tensor[train_indices]\n",
    "        test_data = tensor[test_indices]\n",
    "        data_tensors.extend((train_data, test_data))\n",
    "    return data_tensors\n",
    "    \n",
    "class TorchDataset(Dataset):\n",
    "    def __init__(self, seq2seq_tensor, enc_window=120, dec_window=120):\n",
    "        assert seq2seq_tensor.ndim == 2\n",
    "        assert seq2seq_tensor.shape[0] > enc_window + dec_window, f'{seq2seq_tensor.shape} | {enc_window} | {dec_window}'\n",
    "        self._data = seq2seq_tensor\n",
    "        self.enc_window = enc_window\n",
    "        self.dec_window = dec_window\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return (self._data.shape[0] - (self.enc_window + self.dec_window), 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        enc_data = self._data[index - self.enc_window:index,:]\n",
    "        dec_data = self._data[index:self.dec_window + index,:]\n",
    "        return enc_data, dec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466936f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data_load_fn(\n",
    "    dataset_samples=100,\n",
    "    size=2048,\n",
    "    slopes=np.linspace(0.0001, .001, 100),\n",
    "    n_periods=45,\n",
    "    enc_window = 128,\n",
    "    dec_window = 128,\n",
    "    plot=True,\n",
    "):\n",
    "    arr_dict = dict()\n",
    "\n",
    "    for slope in slopes:\n",
    "        arr = WaveGen(size=size).linear_phase(n_periods=n_periods).cos().amp(2).t_noise(std=.01, dof=2).sample(n_samples=1).samples\n",
    "        trend = np.exp(np.cumsum(np.log(np.random.normal(slope, .005, size=size) + 1))) - 1\n",
    "        arr_dict[slope] = np.squeeze(arr + trend)\n",
    "\n",
    "    if plot:\n",
    "        for slope in np.random.choice(slopes, size=3):\n",
    "            plt.figure(figsize=(15,5))\n",
    "            plt.plot(arr_dict[slope].squeeze())\n",
    "            plt.show()\n",
    "    \n",
    "    data = torch.from_numpy(np.stack(list(arr_dict.values()), axis=0))\n",
    "    split_idx = int(data.shape[0]*.8)\n",
    "    train_data = data[:split_idx]\n",
    "    test_data = data[split_idx:]\n",
    "\n",
    "    def data_load():\n",
    "        train_dataset = TorchDataset(train_data.transpose(0,1), enc_window=enc_window, dec_window=dec_window)\n",
    "        test_dataset = TorchDataset(test_data.transpose(0,1), enc_window=enc_window, dec_window=dec_window)\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    return data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ce24b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SineCNNLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size,\n",
    "        output_size=1,\n",
    "        out_channels=16, \n",
    "        kernel_size=2, \n",
    "        stride=1, \n",
    "        drop=.4, \n",
    "        hidden_size=32,\n",
    "        num_layers=1,\n",
    "        **extra,\n",
    "    ):\n",
    "        super(SineCNNLSTM, self).__init__()\n",
    "        \n",
    "#         conv1_out_shape = (input_size - kernel_size) // stride + 1\n",
    "#         pool_out_shape = (conv1_out_shape - pool_kernel) // pool_kernel + 1\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
    "        self.lstm = nn.LSTM(out_channels, hidden_size, num_layers=num_layers, dropout=drop)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.output = nn.Sigmoid()\n",
    "        return\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        x = self.lstm(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a42075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SineCNNLSTM2(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        enc_window,\n",
    "        dec_window,\n",
    "        hidden_dim=64,\n",
    "        output_dim=128,\n",
    "        n_lstm_layers=3,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        drop=.4,\n",
    "    ):\n",
    "        super(SineCNNLSTM, self).__init__()\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.enc_window = enc_window\n",
    "        self.dec_window = dec_window\n",
    "        \n",
    "        self.conv_in = self.single_conv(1, hidden_dim)\n",
    "        self.conv_hidden = self.single_conv(hidden_dim, hidden_dim)\n",
    "        self.conv_out = self.single_conv(hidden_dim, output_dim)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.lstm = nn.LSTM(output_dim, hidden_dim, num_layers=n_lstm_layers, dropout=drop)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        return\n",
    "        \n",
    "    def single_conv(self, in_channels, out_channels):\n",
    "        layer = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels, \n",
    "                out_channels, \n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    def conv_forward(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.conv_hidden(x)\n",
    "        x = self.conv_out(x)\n",
    "        print(x.shape)\n",
    "        x = self.gap(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.cat([\n",
    "            self.conv_forward(x[i:i+self.enc_window]) \n",
    "            for i \n",
    "            in range(x.shape[0] - self.enc_window)\n",
    "        ])\n",
    "        print('pre-lstm', x.shape)\n",
    "        x = self.lstm(x)\n",
    "        x = self.activation(x)\n",
    "        print('post-lstm', x.shape)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        label = label[i+self.enc_window:i+self.enc_window+self.dec_window]\n",
    "        loss = self.criterion(pred, label)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891a41d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
    "def train_lstm(\n",
    "    config,\n",
    "    load_data_fn,\n",
    "    load_model_fn,\n",
    "    val_split=.8,\n",
    "):\n",
    "    model = load_model_fn(**config)\n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=config['lr'])\n",
    "    checkpoint = session.get_checkpoint()\n",
    "    \n",
    "    if checkpoint:\n",
    "        checkpoint_state = checkpoint.to_dict()\n",
    "        start_epoch = checkpoint_state['epoch']\n",
    "        net.load_state_dict(checkpoint_state['net_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint_state['optimizer_state_dict'])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "    \n",
    "    train_dataset, test_dataset = data_load_fn()\n",
    "    k = int(len(train_dataset) * val_split)\n",
    "    train_dataset, val_dataset = train_dataset[:k], train_dataset[k:]\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "    for epoch in range(start_epoch, 10):\n",
    "        running_train_loss = 0.\n",
    "        running_test_loss = 0.\n",
    "        for (train_data, train_labels), (test_data, test_labels) in zip(train_dataloader, test_dataloader):\n",
    "            for i in range(train_data.shape[0]):\n",
    "                optimizer.zero_grad()\n",
    "                train_output = model(train_data[i])\n",
    "\n",
    "                train_loss = criterion(train_output, train_labels[i])       \n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                running_train_loss += train_loss.item()\n",
    "\n",
    "            for i in range(test_data.shape[0]):\n",
    "                with torch.no_grad():\n",
    "                    test_output = model(test_data[i])\n",
    "                    test_loss = criterion(test_output, test_labels[i])\n",
    "                    running_test_loss += test_loss.item()\n",
    "                \n",
    "            checkpoint_data = {\n",
    "                'epoch' : epoch,\n",
    "#                 'net_state_dict' : model.state_dict(),\n",
    "                'optimizer_state_dict' : optimizer.state_dict(),\n",
    "            }\n",
    "            train.report(checkpoint_data)\n",
    "        if epoch == 9:\n",
    "            torch.save(model.state_dict(), './model.pth')\n",
    "#             checkpoint = Checkpoint.from_dict(checkpoint_data)\n",
    "            \n",
    "#             session.report(\n",
    "#                 {'loss' : test_loss / test_data.shape[0]},\n",
    "#                 checkpoint=checkpoint,\n",
    "#             )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d117679",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def hyperparameter_tune(input_size=128, output_size=128, cpus=4, num_samples=10, max_t=100, grace_period=2, reduction_factor=2):\n",
    "    data_load_fn = get_data_load_fn(enc_window=input_size, dec_window=output_size)\n",
    "    model_load_fn = lambda x : SineCNNLSTM(input_size, output_size, **x)\n",
    "    \n",
    "    config = {\n",
    "        'out_channels' : [2,4,8,16],\n",
    "        'kernel_size' : [2,8,24,48,96,256],\n",
    "        'stride' : [1,2,4,8,24],\n",
    "        'drop' : [.2, .4, .6],\n",
    "        'hidden_size' : [8, 16, 32, 64],\n",
    "        'num_layers' : [2,4,8],\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric='loss',\n",
    "        mode='min',\n",
    "        max_t=max_t,\n",
    "        grace_period=grace_period,\n",
    "        reduction_factor=reduction_factor,\n",
    "    )\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        partial(train_lstm, data_load_fn, model_load_fn, val_split=.8),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            num_samples=20,\n",
    "            scheduler=scheduler,\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "    result = tuner.fit()\n",
    "    \n",
    "    best_trial = result.get_best_result('loss', mode='min')\n",
    "    print(best_trial)\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final test loss: {best_trial.last_result['loss']}\")\n",
    "    \n",
    "    best_model = model_load_fn(\n",
    "        out_channels=best_trial.config['out_channels'], \n",
    "        kernel_size=best_trial.config['kernel_size'], \n",
    "        stride=best_trial.config['stride'],\n",
    "        drop=best_trial.config['drop'],\n",
    "        hidden_size=best_trial.config['hidden_size'],\n",
    "        num_layers=best_trial.config['num_layers'],\n",
    "    )\n",
    "#     best_checkpoint_data = best_trial.checkpoint.to_air_checkpoint().to_dict()\n",
    "\n",
    "    state_dict = torch.load(os.path.join(best_model.path, 'model.pth'))\n",
    "    best_model.load_state_dict(state_dict)\n",
    "    return best_model\n",
    "\n",
    "best_model = hyperparameter_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13517c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731fa5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

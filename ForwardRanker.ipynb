{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f89782",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchbnn\n",
    "%pip install pytorch-lightning\n",
    "%pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as nnl # polars is pl\n",
    "import matplotlib.pyplot as plt\n",
    "import torchbnn as bnn\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "from copy import deepcopy\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from wave_generator import WaveGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48119090",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],[4,1],[5,6]])\n",
    "display(a)\n",
    "display(torch.argsort(a, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5935513",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for phase in [0.2, 1.07, 1.8, 2.45, 3.26]:\n",
    "    large_wave = WaveGen(size=2048).linear_phase(phase).cos().amp(.5).t_noise(std=.05, dof=3).sample(1).samples.squeeze(axis=0)\n",
    "    plt.plot(large_wave, label=str(phase))\n",
    "plt.title('Noisy Sine Target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ordinal_waves(phases, size=2048):\n",
    "    waves = list()\n",
    "    for phase in phases:\n",
    "        wave = WaveGen(size=size).linear_phase(phase).cos().amp(.5).t_noise(std=.05, dof=3).sample(1).samples.squeeze(axis=0)\n",
    "        wave = np.diff(wave)\n",
    "        waves.append(wave)\n",
    "    continuous_wave = torch.from_numpy(np.stack(waves, axis=1)).float()\n",
    "    ordinal_wave = torch.argsort(continuous_wave, dim=1).float() / (continuous_wave.shape[1] - 1)\n",
    "    return continuous_wave, ordinal_wave\n",
    "\n",
    "size = 4096\n",
    "phases = [0.2, 1.07, 1.8, 2.45, 3.26]\n",
    "continuous_wave, ordinal_wave = create_ordinal_waves(phases, size=size)\n",
    "display(ordinal_wave.shape, ordinal_wave.min().item(), ordinal_wave.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardRankDataset(Dataset):\n",
    "    def __init__(self, continous_wave, ordinal_wave, train_length=100, test_length=100, gap=100):\n",
    "        assert continuous_wave.shape == ordinal_wave.shape, f'Size mismatch, {continuous_wave.shape} != {ordinal_wave.shape}'\n",
    "        if not ordinal_wave.dim() == 2:\n",
    "            raise ValueError('Expected 2 dimensional tensor with last dimension shape > 1')\n",
    "            \n",
    "        self._length = continuous_wave.shape[0]\n",
    "        self._output_size = ordinal_wave.shape[1]\n",
    "        self._cont = continuous_wave\n",
    "        self._rank = ordinal_wave\n",
    "            \n",
    "        self.train_length = train_length\n",
    "        self.test_length = test_length\n",
    "        self.gap = gap\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self._length, self._output_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, start_idx):\n",
    "        if isinstance(start_idx, slice):\n",
    "            raise NotImplementedError('Only integers, not slices, are acceptable')\n",
    "            \n",
    "        in_indices = torch.linspace(\n",
    "            start_idx, \n",
    "            start_idx + self.train_length, \n",
    "            self.train_length, \n",
    "            dtype=torch.int\n",
    "        )\n",
    "        forward_indices = torch.linspace(\n",
    "            start_idx + self.train_length + self.gap, \n",
    "            start_idx + self.train_length + self.gap + self.test_length,\n",
    "            self.test_length, \n",
    "            dtype=torch.int\n",
    "        )\n",
    "        back_data = self._cont[in_indices]\n",
    "        forw_data = self._rank[forward_indices]\n",
    "        return back_data, forw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7da60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torchmetrics\n",
    "import torchmetrics as tm\n",
    "\n",
    "class HorizontalRanker(nnl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features,\n",
    "        n_output_features,\n",
    "        n_hidden_features=16,\n",
    "        loss='tau',\n",
    "    ):\n",
    "        super(HorizontalRanker, self).__init__()\n",
    "        self.input = nn.Linear(n_input_features, n_hidden_features)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.hidden = nn.Linear(n_hidden_features, n_hidden_features // 2)\n",
    "        self.output = nn.Linear(n_hidden_features // 2, n_output_features)\n",
    "        \n",
    "        if loss_id == 'tau':\n",
    "            self.c = tm.KendallRankCorrCoef()\n",
    "        elif loss_id == 'spearman':\n",
    "            self.c = tm.SpearmanCorrCoef()\n",
    "        elif loss_id == 'mae':\n",
    "            self.c = tm.MeanAbsoluteError()\n",
    "        elif loss_id == 'contingency':\n",
    "            self.c = tm.PearsonsContingencyCoefficient(n_output_features)\n",
    "        elif loss_id == 'ranking_precision':\n",
    "            self.c = tm.MultilabelRankingAveragePrecision(n_output_features)\n",
    "        elif loss_id == 'ranking_loss':\n",
    "            self.c = tm.MultilabelRankingLoss(n_output_features)\n",
    "        return\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "#         x = torch.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx, min_weight=.05):\n",
    "        x, y = train_batch\n",
    "        y_hat = self.forward(x)\n",
    "#         penalty_term = 1e5 if torch.min(self.weights) < min_weight else 0\n",
    "        loss = self.c(y_hat, y) # + penalty_term\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx, min_weight=.05):\n",
    "        x, y = val_batch\n",
    "        y_hat = self.forward(x)\n",
    "#         penalty_term = 1e5 if torch.min(self.weights) < min_weight else 0\n",
    "        loss = self.c(y_hat, y)  # + penalty_term\n",
    "        self.log('val_loss', loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BinaryRankAggregator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features,\n",
    "        n_output_features,\n",
    "#         n_hidden_features=16,\n",
    "        loss='tau',\n",
    "        all_weight=.5,\n",
    "        comb_weight=.5,\n",
    "    ):\n",
    "        self.n_input_features = n_input_features\n",
    "        self.n_output_features = n_output_features\n",
    "        self.n_hidden_features = n_hidden_features\n",
    "        self.all_weight = all_weight\n",
    "        self.comb_weight = comb_weight\n",
    "        \n",
    "        self.n_subnets = math.comb(n_output_features, 2)\n",
    "        assert self.n_subnets < 64, 'That`s a lot of subnets'\n",
    "        self.unique_indices = list(range(self.n_subnets))\n",
    "        self.subnet_indices = list(itertools.combinations(self.unique_indices, 2))\n",
    "        self.index_dict = dict.from_keys(self.unique_indices, list())\n",
    "#         self.net_dict = dict()\n",
    "        \n",
    "        # Binary Partially Connected Layer\n",
    "#         self.binput_layer = nn.Linear(self.n_input_features, self.n_subnets)\n",
    "        self.full_subnets = list()    \n",
    "        for i, (ind1, ind2) in enumerate(range(self.subnet_indices)):\n",
    "            assert ind1 in self.index_dict\n",
    "            assert ind2 in self.index_dict\n",
    "            \n",
    "            self.full_subnets.append(\n",
    "                nn.Linear(n_input_features, 1)\n",
    "            )\n",
    "            self.index_dict[ind1].append(i)\n",
    "            self.index_dict[ind2].append(i)\n",
    "            # this shouldn't be strictly necessary\n",
    "#             self.net_dict[(ind1, ind2)] = i\n",
    "            \n",
    "        for i, nodes in self.index_dict.items():\n",
    "            assert len(nodes) == self.n_subnets - 1, f'{len(nodes)} != {self.n_output_features - 1}'\n",
    "            \n",
    "        self.partial_subnets = list()\n",
    "        for i in self.unique_indices:\n",
    "            self.partial_subnets.append(\n",
    "                nn.Linear(self.n_output_features - 1, 1)\n",
    "            )\n",
    "            \n",
    "#         self.bagg_layer = nn.Linear(self.n_subnets, n_output_features)\n",
    "        #########################\n",
    "        \n",
    "        # Regular Feedforward Net\n",
    "        self.hinput_layer = nn.Linear(n_input_features, n_hidden_features)\n",
    "        self.hagg_layer = nn.Linear(n_hidden_features, n_output_features)\n",
    "        #########################\n",
    "        \n",
    "        self.output_layer = nn.Linear(n_output_features, n_output_features)\n",
    "        \n",
    "        self.tau_loss = tm.KendallRankCorrCoef()\n",
    "        self.bin_loss = nn.BCELoss()\n",
    "        return\n",
    "\n",
    "    def partial_forward(self, x):\n",
    "        initial_features = [full_subnet(x) for full_subnet in self.full_subnets]\n",
    "        binary_x = torch.cat(initial_features, dim=0)\n",
    "        \n",
    "        partial_features = list()\n",
    "        for i, partial_subnet in enumerate(self.partial_subnets):\n",
    "            partial_feature = torch.cat([initial_features[j] for j in self.index_dict[i]], dim=0)\n",
    "            partial_features.append(partial_subnet(partial_feature))\n",
    "            \n",
    "        feature_x = torch.cat(partial_features, dim=0)\n",
    "        return feature_x, binary_x\n",
    "    \n",
    "    def full_forward(self, x):\n",
    "        x = self.hinput_layer(x)\n",
    "        x = self.hagg_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.full_forward(x)\n",
    "        x2, binary_x = self.partial_forward(x)\n",
    "        x = x1 + x2\n",
    "        x = self.output_layer(x)\n",
    "        return x, binary_x\n",
    "    \n",
    "    def loss(self, all_pred, comb_pred, all_truth, comb_truth):\n",
    "        tau_loss = -self.tau_loss(all_pred, all_truth)\n",
    "        bin_loss = self.bin_loss(comb_pred, comb_truth)\n",
    "        loss = self.tau_loss * self.all_weight + self.bin_loss * self.comb_weight\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec9b30",
   "metadata": {},
   "source": [
    "[K Fold Ensembling](https://www.sciencedirect.com/science/article/abs/pii/S0304407622000975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1908053",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_size = int(size * .8)\n",
    "test_size = size - train_size - 1\n",
    "\n",
    "continuous_train = continuous_wave[:train_size,:]\n",
    "ordinal_train = ordinal_wave[:train_size,:]\n",
    "\n",
    "continuous_val = continuous_wave[train_size:]\n",
    "ordinal_val = ordinal_wave[train_size:]\n",
    "\n",
    "train_loader = DataLoader(ForwardRankDataset(continuous_train, ordinal_train), batch_size=batch_size)\n",
    "val_loader = DataLoader(ForwardRankDataset(continuous_val, ordinal_val), batch_size=batch_size)\n",
    "\n",
    "model = HorizontalRanker(\n",
    "    train_loader._output_size,\n",
    "    train_loader._output_size,\n",
    "    n_hidden_features=16,\n",
    "    loss='tau',\n",
    ").float()\n",
    "\n",
    "trainer = nnl.Trainer(precision=16, max_epochs=100, callbacks=[EarlyStopping(monitor='val_loss', min_delta=0., patience=5)])\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac483a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('[Tensorboard](http://localhost:6006/#timeseries)'))\n",
    "!tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47855c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f89782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchbnn\n",
    "# %pip install pytorch-lightning\n",
    "# %pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as nnl # polars is pl\n",
    "import matplotlib.pyplot as plt\n",
    "import torchbnn as bnn\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "from pytorch_lightning.callbacks import LearningRateFinder, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "from copy import deepcopy\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from wave_generator import WaveGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5935513",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for phase in [0.2, 1.07, 1.8, 2.45, 3.26]:\n",
    "    large_wave = WaveGen(size=2048).linear_phase(phase).cos().amp(.5).t_noise(std=.05, dof=3).sample(1).samples.squeeze(axis=0)\n",
    "    plt.plot(large_wave, label=str(phase))\n",
    "    \n",
    "plt.title('Noisy Sine Target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ordinal_waves(phases, size=2048):\n",
    "    waves = list()\n",
    "    for phase in phases:\n",
    "        wave = WaveGen(size=size).linear_phase(phase).cos().amp(.5).t_noise(std=.05, dof=3).sample(1).samples.squeeze(axis=0)\n",
    "        wave = np.diff(wave)\n",
    "        waves.append(wave)\n",
    "    continuous_wave = torch.from_numpy(np.stack(waves, axis=1)).float()\n",
    "    ordinal_wave = torch.argsort(continuous_wave, dim=1).float() / (continuous_wave.shape[1] - 1)\n",
    "    assert continuous_wave.shape == ordinal_wave.shape\n",
    "    return continuous_wave, ordinal_wave\n",
    "\n",
    "size = 4096\n",
    "phases = [0.2, 1.07, 1.8, 2.45, 3.26]\n",
    "continuous_wave, ordinal_wave = create_ordinal_waves(phases, size=size)\n",
    "display(ordinal_wave.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardRankDataset(Dataset):\n",
    "    def __init__(self, continuous_wave, ordinal_wave, pairwise=False, train_length=1, test_length=1, gap=100):\n",
    "        assert continuous_wave.shape == ordinal_wave.shape, f'Size mismatch, {continuous_wave.shape} != {ordinal_wave.shape}'\n",
    "        if not ordinal_wave.dim() == 2:\n",
    "            raise ValueError('Expected 2 dimensional tensor with last dimension shape > 1')\n",
    "            \n",
    "        self._length = continuous_wave.shape[0]\n",
    "        self._output_size = ordinal_wave.shape[1]\n",
    "        self._unique_indices = list(range(self._output_size))\n",
    "        self._cont = continuous_wave\n",
    "        self._rank = ordinal_wave\n",
    "            \n",
    "        self.train_length = train_length\n",
    "        self.test_length = test_length\n",
    "        self.gap = gap\n",
    "        self.pairwise = pairwise\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self._length - 1 - self.test_length - self.gap - self.train_length, self._output_size - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.shape[0]\n",
    "\n",
    "    def __getitem__(self, start_idx):\n",
    "        if isinstance(start_idx, slice):\n",
    "            raise NotImplementedError('Only integers, not slices, are acceptable')\n",
    "            \n",
    "        if self.train_length > 1 or self.test_length > 1:\n",
    "            in_indices = torch.linspace(\n",
    "                start_idx, \n",
    "                start_idx + self.train_length, \n",
    "                self.train_length, \n",
    "                dtype=torch.int\n",
    "            )\n",
    "            forward_indices = torch.linspace(\n",
    "                start_idx + self.train_length + self.gap, \n",
    "                start_idx + self.train_length + self.gap + self.test_length,\n",
    "                self.test_length, \n",
    "                dtype=torch.int\n",
    "            )\n",
    "        else:\n",
    "            in_indices = start_idx\n",
    "            forward_indices = start_idx + self.gap + 1\n",
    "            \n",
    "        back_data = self._cont[in_indices,:]\n",
    "        forw_data = self._rank[forward_indices,:]\n",
    "#         assert back_data.shape == (self.train_length, self._output_size), back_data.shape\n",
    "#         assert forw_data.shape == (self.test_length, self._output_size), forw_data.shape\n",
    "        if self.pairwise:\n",
    "        # this could be much more efficient if it was ranked at the __init__ call\n",
    "            pair_data = list()\n",
    "            for i, (idx1, idx2) in enumerate(itertools.combinations(self._unique_indices, 2)):\n",
    "                pair_data.append(forw_data[idx1] < forw_data[idx2])\n",
    "            pair_data = torch.tensor(pair_data).float()\n",
    "            return back_data, forw_data, pair_data\n",
    "        else:\n",
    "            return back_data, forw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torchmetrics as tm\n",
    "\n",
    "class BinaryRankAggregator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features,\n",
    "        n_output_features,\n",
    "        n_hidden_features=16,\n",
    "        loss='tau',\n",
    "        all_weight=.5,\n",
    "        comb_weight=.5,\n",
    "    ):\n",
    "        super(BinaryRankAggregator, self).__init__()\n",
    "        self.n_input_features = n_input_features\n",
    "        self.n_output_features = n_output_features\n",
    "        self.n_hidden_features = n_hidden_features\n",
    "        self.all_weight = all_weight\n",
    "        self.comb_weight = comb_weight\n",
    "        \n",
    "        self.unique_indices = list(range(n_output_features))\n",
    "        self.subnet_indices = list(itertools.combinations(self.unique_indices, 2))\n",
    "        self.n_subnets = len(self.subnet_indices)\n",
    "        assert self.n_subnets < 64, 'That`s a lot of subnets'\n",
    "        \n",
    "        self.index_dict = {idx : list() for idx in self.unique_indices}\n",
    "        \n",
    "        # Binary Partially Connected Layer\n",
    "        self.full_subnets = list()    \n",
    "        for i, (idx1, idx2) in enumerate(self.subnet_indices):\n",
    "            assert idx1 in self.index_dict\n",
    "            assert idx2 in self.index_dict\n",
    "            \n",
    "            self.full_subnets.append(\n",
    "                nn.Linear(n_input_features, 1)\n",
    "            )\n",
    "            self.index_dict[idx1].append(i)\n",
    "            self.index_dict[idx2].append(i)\n",
    "            \n",
    "        for i, nodes in self.index_dict.items():\n",
    "            assert len(nodes) == self.n_output_features - 1, f'{len(nodes)} != {self.n_output_features - 1}'\n",
    "            \n",
    "        self.partial_subnets = list()\n",
    "        for i in self.unique_indices:\n",
    "            partial_subnet = nn.Linear(self.n_output_features - 1, 1)\n",
    "            self.partial_subnets.append(partial_subnet)\n",
    "            \n",
    "#         self.bagg_layer = nn.Linear(self.n_subnets, n_output_features)\n",
    "        #########################\n",
    "        \n",
    "        # Regular Feedforward Net\n",
    "        self.hinput_layer = nn.Linear(n_input_features, n_hidden_features)\n",
    "        self.hagg_layer = nn.Linear(n_hidden_features, n_output_features)\n",
    "        #########################\n",
    "        \n",
    "        self.output_layer = nn.Linear(n_output_features, n_output_features)\n",
    "        \n",
    "        self.tau_loss = tm.KendallRankCorrCoef(num_outputs=n_output_features)\n",
    "        self.bin_loss = nn.BCEWithLogitsLoss()\n",
    "        return\n",
    "\n",
    "    def partial_forward(self, x):\n",
    "        initial_features = [full_subnet(x) for full_subnet in self.full_subnets]\n",
    "        \n",
    "        partial_features = list()\n",
    "        for i, partial_subnet in enumerate(self.partial_subnets):\n",
    "            partial_feature = torch.cat([initial_features[j] for j in self.index_dict[i]], dim=1)\n",
    "            partial_features.append(partial_subnet(partial_feature))\n",
    "            \n",
    "        feature_x = torch.cat(partial_features, dim=1)\n",
    "        binary_x = torch.cat(initial_features, dim=1)\n",
    "        return feature_x, binary_x\n",
    "    \n",
    "    def norm(self, x):\n",
    "        x = (x - torch.min(x))\n",
    "        x = x / torch.max(x)\n",
    "        return x\n",
    "        \n",
    "    def full_forward(self, x):\n",
    "        x = self.hinput_layer(x)\n",
    "        x = self.hagg_layer(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.full_forward(x)\n",
    "        x2, binary_x = self.partial_forward(x)\n",
    "        x = x1 + x2\n",
    "        x = self.output_layer(x)\n",
    "        x = self.norm(x)\n",
    "        return x, binary_x\n",
    "    \n",
    "    def loss(self, all_pred, comb_pred, all_truth, comb_truth):\n",
    "        tau_loss = -self.tau_loss(all_pred, all_truth)\n",
    "        bin_loss = self.bin_loss(comb_pred, comb_truth)\n",
    "        loss = torch.mean(tau_loss * self.all_weight + bin_loss * self.comb_weight)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_size = int(size * .8)\n",
    "test_size = size - train_size - 1\n",
    "n_epochs = 64\n",
    "\n",
    "assert continuous_wave.shape == ordinal_wave.shape\n",
    "continuous_train = continuous_wave[:train_size,:]\n",
    "ordinal_train = ordinal_wave[:train_size,:]\n",
    "assert continuous_wave.shape == ordinal_wave.shape\n",
    "\n",
    "continuous_val = continuous_wave[train_size:,:]\n",
    "ordinal_val = ordinal_wave[train_size:,:]\n",
    "assert continuous_wave.shape == ordinal_wave.shape\n",
    "print('Continuous Wave Shape', continuous_wave.shape)\n",
    "print('Ordinal Wave Shape', ordinal_wave.shape)\n",
    "\n",
    "n_features = continuous_wave.shape[1]\n",
    "print('Number of Features', n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e23173",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ForwardRankDataset(continuous_train, ordinal_train, pairwise=True)\n",
    "val_dataset = ForwardRankDataset(continuous_val, ordinal_val, pairwise=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "bra_model = BinaryRankAggregator(\n",
    "        n_features,\n",
    "        n_features,\n",
    "        loss='tau',\n",
    "        all_weight=.5,\n",
    "        comb_weight=.5,\n",
    ").float()\n",
    "losses = list()\n",
    "optimizer = torch.optim.NAdam(bra_model.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "\n",
    "def plot_iteration_loss(train_loss, val_loss, title=''):\n",
    "    assert len(train_loss) and len(val_loss)\n",
    "    data = pd.DataFrame({\n",
    "        'train_loss' : train_loss,\n",
    "        'validation_loss' : val_loss,\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    sns.lineplot(data=data, dashes=False)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "epoch_losss = list()\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch', epoch, end='\\r')\n",
    "    for (train_input, train_forw_output, train_pair_output), (val_input, val_forw_output, val_pair_output) in zip(train_loader, val_loader):\n",
    "        train_forw_pred, train_pair_pred = bra_model(train_input)\n",
    "        loss = bra_model.loss(train_forw_pred, train_pair_pred, train_forw_output, train_pair_output)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_forw_pred, val_pair_pred = bra_model(val_input)\n",
    "            val_loss = bra_model.loss(val_forw_pred, val_pair_pred, val_forw_output, val_pair_output)\n",
    "\n",
    "        losses.append((loss.item(), val_loss.item()))\n",
    "#     plot_iteration_loss(losses)\n",
    "    epoch_train_losss, epoch_val_losss = zip(*losses)\n",
    "    epoch_losss.append((np.mean(epoch_train_losss), np.mean(epoch_val_losss)))\n",
    "    losses.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_losss, all_val_losss = zip(*epoch_losss)\n",
    "print(all_train_losss)\n",
    "plot_iteration_loss(all_train_losss, all_val_losss, title='Epoch Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7da60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorizontalRanker(nnl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features,\n",
    "        n_output_features,\n",
    "        n_hidden_features=16,\n",
    "        loss_id='tau',\n",
    "    ):\n",
    "        super(HorizontalRanker, self).__init__()\n",
    "        self.input = nn.Linear(n_input_features, n_hidden_features)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.hidden = nn.Linear(n_hidden_features, n_hidden_features // 2)\n",
    "        self.output = nn.Linear(n_hidden_features // 2, n_output_features)\n",
    "        \n",
    "        if loss_id == 'tau':\n",
    "            self.c = tm.KendallRankCorrCoef()\n",
    "        elif loss_id == 'spearman':\n",
    "            self.c = tm.SpearmanCorrCoef()\n",
    "        elif loss_id == 'mae':\n",
    "            self.c = tm.MeanAbsoluteError()\n",
    "        elif loss_id == 'contingency':\n",
    "            self.c = tm.PearsonsContingencyCoefficient(n_output_features)\n",
    "        elif loss_id == 'ranking_precision':\n",
    "            self.c = tm.MultilabelRankingAveragePrecision(n_output_features)\n",
    "        elif loss_id == 'ranking_loss':\n",
    "            self.c = tm.MultilabelRankingLoss(n_output_features)\n",
    "        return\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "#         x = torch.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx, min_weight=.05):\n",
    "        x, y = train_batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        loss = self.c(y_hat, y) # + penalty_term\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx, min_weight=.05):\n",
    "        x, y = val_batch\n",
    "        y_hat = self.forward(x)\n",
    "        \n",
    "        loss = self.c(y_hat, y)  # + penalty_term\n",
    "        self.log('val_loss', loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1908053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ForwardRankDataset(continuous_train, ordinal_train, pairwise=False)\n",
    "val_dataset = ForwardRankDataset(continuous_val, ordinal_val, pairwise=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "es_callback = EarlyStopping(monitor='val_loss', min_delta=0., patience=5)\n",
    "lr_callback = LearningRateFinder()\n",
    "mc_callabck = ModelCheckpoint(dirpath='model_checkpoints/')\n",
    "\n",
    "print(train_dataset._output_size)\n",
    "model = HorizontalRanker(\n",
    "    train_dataset._output_size,\n",
    "    train_dataset._output_size,\n",
    "    n_hidden_features=16,\n",
    "    loss_id='mae',\n",
    ").float()\n",
    "\n",
    "trainer = nnl.Trainer(\n",
    "    precision='bf16-mixed', \n",
    "    max_epochs=n_epochs, \n",
    "    callbacks=[es_callback]\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac483a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('[Tensorboard](http://localhost:6006/#timeseries)'))\n",
    "!tensorboard --logdir ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

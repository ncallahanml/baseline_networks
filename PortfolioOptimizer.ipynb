{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b41cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --user \"jax[cpu]\"\n",
    "# %pip install --user flax\n",
    "# %pip install --user optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91aaffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import flax\n",
    "import optax\n",
    "\n",
    "# not a fan of the FLAX nn import, especially considering most models in this repository us PyTorch nn\n",
    "import flax.linen as ln\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211e1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(ln.Module):\n",
    "    num_outputs : int\n",
    "        \n",
    "    @ln.compact\n",
    "    def __call__(self, x):\n",
    "        x = ln.Dense(features=self.num_outputs)(x)\n",
    "        x = ln.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "# https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.ipynb#scrollTo=3qjS60Zl-I2_\n",
    "model = Linear(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0549cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "class GaussianReturns(Dataset):\n",
    "    def __init__(self, size, cov, mean, cov_noise=None, noise_batch=32, reshuffle=True, seed=None):\n",
    "        super().__init__()\n",
    "        cov = np.asarray(cov)\n",
    "        mean = np.asarray(mean)\n",
    "        self._data = self._generate_returns(size, mean, cov, cov_noise, noise_batch, reshuffle)\n",
    "        return\n",
    "        \n",
    "    def _noisy_cov(self, cov, cov_noise):\n",
    "        return np.clip(cov + np.random.normal(cov.shape) * cov_noise, 0, 1)\n",
    "        \n",
    "    def _generate_returns(self, size, mean, cov, cov_noise, noise_batch, reshuffle):\n",
    "        n_even = size // noise_batch\n",
    "        size_uneven = size % noise_batch\n",
    "        samples = list()\n",
    "        assert cov.shape[0] == cov.shape[1] == mean.shape[0], f'{cov.shape} | {mean.shape}'\n",
    "        \n",
    "        for _ in range(n_even):\n",
    "            # should provide option to input list of cov_noise offsets\n",
    "            ncov = cov if cov_noise is None else self._noisy_cov(cov, cov_noise)\n",
    "            sample = st.multivariate_normal(mean, cov).rvs(size=noise_batch)\n",
    "            assert sample.shape == (noise_batch, cov.shape[0])\n",
    "            samples.append(sample)\n",
    "            \n",
    "        if size_uneven:\n",
    "            key1, key2 = jax.random.split(self.rng, num=2)\n",
    "            ncov = cov if cov_noise is None else self._noisy_cov(cov, cov_noise)\n",
    "            sample = st.multivariate_normal(mean, cov).rvs(size=size_uneven)\n",
    "            samples.append(sample)\n",
    "            \n",
    "        return_array = np.concatenate(samples, axis=0)\n",
    "        assert return_array.shape == (size, cov.shape[1])\n",
    "        if reshuffle:\n",
    "            return_array = np.random.permutation(return_array)\n",
    "        return return_array\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._data.shape[0]\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self._data.shape\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self._data[idx]\n",
    "        return data_point\n",
    "    \n",
    "\n",
    "# This collate function is taken from the JAX tutorial with PyTorch Data Loading\n",
    "# https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "dataset = GaussianReturns(256, [[.001, .0001], [.0001, .001]], [.001, .002])\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857c3c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "rng, inpt_rng, init_rng = jax.random.split(rng, 3)\n",
    "\n",
    "# should be changed to He initialization?\n",
    "inpt_array = jax.random.normal(inpt_rng, (8, 2))\n",
    "params = model.init(init_rng, inpt_array)\n",
    "optimizer = optax.sgd(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052e348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "\n",
    "model_state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3f6cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_loss(state, params, data):\n",
    "    logits = state.apply_fn(params, data)\n",
    "#     pred_labels = (logits > 0).astype(jnp.float32)\n",
    "    weights = ln.softmax(logits)\n",
    "    print(weights.shape)\n",
    "    print(data.shape)\n",
    "    pfl_returns = jnp.dot(data, weights.T).squeeze(-1)\n",
    "    print(pfl_returns)\n",
    "    exp_return = pfl_returns.mean(axis=0)\n",
    "    exp_var = pfl_returns.var(axis=0)\n",
    "    print(exp_return.shape)\n",
    "    \n",
    "    # sharpe\n",
    "    loss = exp_return / exp_var   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cfe21129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(data_loader))\n",
    "# calculate_loss_acc(model_state, model_state.params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2db83ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def train_step(state, batch):\n",
    "    # Gradient function\n",
    "    grad_fn = jax.value_and_grad(\n",
    "        sharpe_loss,  # Function to calculate the loss\n",
    "        argnums=1,  # Parameters are second argument of the function\n",
    "        has_aux=False,\n",
    "    )\n",
    "    loss, grads = grad_fn(state, state.params, batch)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aab7fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def eval_step(state, batch):\n",
    "    # Determine the accuracy\n",
    "    _, acc = calculate_loss_acc(state, state.params, batch)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb498936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(state, dataloader, num_epochs=100):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for batch in dataloader:\n",
    "            state, loss, acc = train_step(state, batch)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34e684ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2)\n",
      "(8, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot select an axis to squeeze out which has size not equal to one, got shape=(8, 8) and dimensions=(1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[76], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(state, dataloader, num_epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m----> 6\u001b[0m         state, loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[74], line 9\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(state, batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit  \u001b[38;5;66;03m# Jit the function for efficiency\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(state, batch):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Gradient function\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(\n\u001b[0;32m      5\u001b[0m         sharpe_loss,  \u001b[38;5;66;03m# Function to calculate the loss\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         argnums\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Parameters are second argument of the function\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m     )\n\u001b[1;32m----> 9\u001b[0m     loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mapply_gradients(grads\u001b[38;5;241m=\u001b[39mgrads)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m state, loss, acc\n",
      "    \u001b[1;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[72], line 7\u001b[0m, in \u001b[0;36msharpe_loss\u001b[1;34m(state, params, data)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(weights\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m----> 7\u001b[0m pfl_returns \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(pfl_returns)\n\u001b[0;32m      9\u001b[0m exp_return \u001b[38;5;241m=\u001b[39m pfl_returns\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:733\u001b[0m, in \u001b[0;36m_forward_method_to_aval.<locals>.meth\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeth\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 733\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maval, name)\u001b[38;5;241m.\u001b[39mfun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:886\u001b[0m, in \u001b[0;36msqueeze\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;129m@util\u001b[39m\u001b[38;5;241m.\u001b[39m_wraps(np\u001b[38;5;241m.\u001b[39msqueeze, lax_description\u001b[38;5;241m=\u001b[39m_ARRAY_VIEW_DOC)\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msqueeze\u001b[39m(a: ArrayLike, axis: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Sequence[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[0;32m    885\u001b[0m   util\u001b[38;5;241m.\u001b[39mcheck_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqueeze\u001b[39m\u001b[38;5;124m\"\u001b[39m, a)\n\u001b[1;32m--> 886\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_squeeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ensure_index_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:896\u001b[0m, in \u001b[0;36m_squeeze\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjnp.squeeze with axis=None is not supported with shape polymorphism\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    895\u001b[0m   axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(a_shape) \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 896\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jax\\_src\\lax\\lax.py:3326\u001b[0m, in \u001b[0;36m_compute_squeeze_shape\u001b[1;34m(shape, dimensions)\u001b[0m\n\u001b[0;32m   3324\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions outside range [0, ndim): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdimensions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal(shape[d], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dimensions):\n\u001b[1;32m-> 3326\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3327\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot select an axis to squeeze out which has size not equal to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3328\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdimensions\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(s \u001b[38;5;28;01mfor\u001b[39;00m i, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(shape) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dims_set)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot select an axis to squeeze out which has size not equal to one, got shape=(8, 8) and dimensions=(1,)"
     ]
    }
   ],
   "source": [
    "trained_model_state = train_model(model_state, dataloader, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d00b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints.save_checkpoint(\n",
    "    ckpt_dir='my_checkpoints/',\n",
    "    target=trained_model_state,\n",
    "    step=100,\n",
    "    prefix='my_model',\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f20f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_state = checkpoints.restore_checkpoint(\n",
    "    ckpt_dir='my_checkpoints/',\n",
    "    target=model_state,\n",
    "    prefix='my_model',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984faa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model.bind(trained_model_state.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

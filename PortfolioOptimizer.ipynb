{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --user \"jax[cpu]\"\n",
    "# %pip install --user flax\n",
    "# %pip install --user optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import flax\n",
    "import jax\n",
    "\n",
    "import scipy.stats as st\n",
    "# not a fan of the FLAX nn import, especially considering most models in this repository us PyTorch nn\n",
    "import flax.linen as ln\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from flax.training import train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ce14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(ln.Module):\n",
    "    num_outputs : int\n",
    "        \n",
    "    @ln.compact\n",
    "    def __call__(self, x):\n",
    "        x = ln.Dense(features=self.num_outputs)(x)\n",
    "        x = ln.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "# https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.ipynb#scrollTo=3qjS60Zl-I2_\n",
    "model = Linear(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5626a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianReturns(Dataset):\n",
    "    def __init__(self, size, cov, mean, cov_noise=None, noise_batch=32, reshuffle=True, seed=None):\n",
    "        super().__init__()\n",
    "        cov = np.asarray(cov)\n",
    "        mean = np.asarray(mean)\n",
    "        self._data = self._generate_returns(size, mean, cov, cov_noise, noise_batch, reshuffle)\n",
    "        return\n",
    "        \n",
    "    def _noisy_cov(self, cov, cov_noise):\n",
    "        return np.clip(cov + np.random.normal(cov.shape) * cov_noise, 0, 1)\n",
    "        \n",
    "    def _generate_returns(self, size, mean, cov, cov_noise, noise_batch, reshuffle):\n",
    "        n_even = size // noise_batch\n",
    "        size_uneven = size % noise_batch\n",
    "        samples = list()\n",
    "        assert cov.shape[0] == cov.shape[1] == mean.shape[0], f'{cov.shape} | {mean.shape}'\n",
    "        \n",
    "        for _ in range(n_even):\n",
    "            # should provide option to input list of cov_noise offsets\n",
    "            ncov = cov if cov_noise is None else self._noisy_cov(cov, cov_noise)\n",
    "            sample = st.multivariate_normal(mean, cov).rvs(size=noise_batch)\n",
    "            assert sample.shape == (noise_batch, cov.shape[0])\n",
    "            samples.append(sample)\n",
    "            \n",
    "        if size_uneven:\n",
    "            key1, key2 = jax.random.split(self.rng, num=2)\n",
    "            ncov = cov if cov_noise is None else self._noisy_cov(cov, cov_noise)\n",
    "            sample = st.multivariate_normal(mean, cov).rvs(size=size_uneven)\n",
    "            samples.append(sample)\n",
    "            \n",
    "        return_array = np.concatenate(samples, axis=0)\n",
    "        assert return_array.shape == (size, cov.shape[1])\n",
    "        if reshuffle:\n",
    "            return_array = np.random.permutation(return_array)\n",
    "        return return_array\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._data.shape[0]\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self._data.shape\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self._data[idx]\n",
    "        return data_point\n",
    "    \n",
    "# This collate function is taken from the JAX tutorial with PyTorch Data Loading\n",
    "# https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "dataset = GaussianReturns(256, [[.001, .0001], [.0001, .001]], [.001, .002])\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26014bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "rng, inpt_rng, init_rng = jax.random.split(rng, 3)\n",
    "\n",
    "inpt_array = jax.random.normal(inpt_rng, (8, 2))\n",
    "params = model.init(init_rng, inpt_array)\n",
    "optimizer = optax.sgd(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_returns(state, params, data):\n",
    "    logits = state.apply_fn(params, data)\n",
    "    weights = ln.softmax(logits)\n",
    "    pfl_returns = jnp.multiply(data, weights).sum(axis=1)    \n",
    "    return pfl_returns\n",
    "    \n",
    "def sharpe_loss(state, params, data):\n",
    "    pfl_returns = dot_returns(state, params, data)\n",
    "#     exp_return = jnp.exp(jnp.sum(jnp.log(pfl_returns + 1))) -1\n",
    "    exp_mean = pfl_returns.mean(axis=0)\n",
    "    exp_var = pfl_returns.var(axis=0)\n",
    "    \n",
    "    # sharpe, minimized instead of maximized\n",
    "    loss = -exp_mean / exp_var   \n",
    "    return loss\n",
    "\n",
    "def cvar_loss(state, params, data):\n",
    "    k = int(data.shape[0] * .05)\n",
    "    pfl_returns = dot_returns(state, params, data)\n",
    "#     exp_return = jnp.exp(jnp.sum(jnp.log(pfl_returns + 1))) -1\n",
    "    exp_mean = jnp.mean(pfl_returns)\n",
    "    exp_cvar = jax.lax.slice(jnp.argpartition(pfl_returns, k), (0,), (k,)).mean()\n",
    "    \n",
    "    # sharpe, minimized instead of maximized\n",
    "    loss = exp_mean / (exp_mean - exp_cvar)   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(data_loader))\n",
    "# calculate_loss_acc(model_state, model_state.params, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d604bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def train_step(state, batch):\n",
    "    # Gradient function\n",
    "    grad_fn = jax.value_and_grad(\n",
    "        cvar_loss,  # Function to calculate the loss\n",
    "        argnums=1,  # Parameters are second argument of the function\n",
    "        has_aux=False,\n",
    "    )\n",
    "    loss, grads = grad_fn(state, state.params, batch)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3014d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit  # Jit the function for efficiency\n",
    "def eval_step(state, batch):\n",
    "    # Determine the accuracy\n",
    "    _, acc = calculate_loss_acc(state, state.params, batch)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1117e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(state, dataloader, num_epochs=100):\n",
    "    losss = list()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        epoch_losss = list()\n",
    "        for batch in dataloader:\n",
    "            state, loss = train_step(state, batch)\n",
    "            epoch_losss.append(loss)\n",
    "        losss.append(jnp.mean(jnp.array(epoch_losss)))\n",
    "            \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(losss)\n",
    "    plt.show()\n",
    "    return state\n",
    "\n",
    "def single_batch_train_model(state, data, num_epochs=100):\n",
    "    losss = list()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        state, loss = train_step(state, data)\n",
    "        losss.append(loss)\n",
    "            \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(losss)\n",
    "    plt.show()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset._data\n",
    "display(data.shape)\n",
    "trained_model_state = train_model(\n",
    "    model_state, \n",
    "    data, \n",
    "    num_epochs=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_state = train_model(\n",
    "    model_state, \n",
    "    dataloader, \n",
    "    num_epochs=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2220c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints.save_checkpoint(\n",
    "    ckpt_dir='my_checkpoints/',\n",
    "    target=trained_model_state,\n",
    "    step=100,\n",
    "    prefix='my_model',\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19729517",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_state = checkpoints.restore_checkpoint(\n",
    "    ckpt_dir='my_checkpoints/',\n",
    "    target=model_state,\n",
    "    prefix='my_model',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model.bind(trained_model_state.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
